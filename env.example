# Example .env configuration

# ============================================================================
# LLM Provider Selection
# ============================================================================
# Options: 'azure' or 'ollama'
# - azure: Use Azure OpenAI (cloud-based, requires API key)
# - ollama: Use local Ollama models (free, runs locally)
LLM_PROVIDER=azure

# ============================================================================
# Azure OpenAI Configuration (when LLM_PROVIDER=azure)
# ============================================================================
AZURE_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_API_KEY=your-api-key
AZURE_DEPLOYMENT=gpt-4o
AZURE_API_VERSION=2024-02-15-preview

# ============================================================================
# Ollama Configuration (when LLM_PROVIDER=ollama)
# ============================================================================
# Ollama server URL (default: http://localhost:11434)
OLLAMA_BASE_URL=http://localhost:11434

# Ollama model to use
# Popular models: llama2, mistral, codellama, mixtral, phi, gemma
# Install models: ollama pull <model-name>
OLLAMA_MODEL=llama2

# Request timeout in seconds (increase for larger models)
OLLAMA_TIMEOUT=120

# ============================================================================
# Embedding Model Configuration
# ============================================================================
EMBEDDING_MODEL=all-MiniLM-L6-v2

# ============================================================================
# Vector Database Configuration
# ============================================================================
VECTOR_DB_PATH=./chroma_db
VECTOR_DB_COLLECTION=documents

# ============================================================================
# Chunking Configuration
# ============================================================================
CHUNK_SIZE=512
CHUNK_OVERLAP=128
MIN_CHUNK_SIZE=50

# ============================================================================
# Retrieval Configuration
# ============================================================================
DEFAULT_TOP_K=5
VECTOR_WEIGHT=0.7
BM25_WEIGHT=0.3

# ============================================================================
# Conversation Configuration
# ============================================================================
ENABLE_CONVERSATION=true
MAX_CONVERSATION_HISTORY=10

# ============================================================================
# LLM Generation Configuration
# ============================================================================
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=200

# ============================================================================
# Reranker Configuration
# ============================================================================
# Options: 'llm' or 'cross_encoder'
# - llm: Uses LLM for reranking (flexible but slower, costs LLM tokens)
# - cross_encoder: Uses cross-encoder model (faster, no API costs)
RERANKER_TYPE=cross_encoder
CROSS_ENCODER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2

# Alternative cross-encoder models:
# - cross-encoder/ms-marco-TinyBERT-L-2-v2 (smallest, fastest)
# - cross-encoder/ms-marco-MiniLM-L-6-v2 (balanced, recommended)
# - cross-encoder/ms-marco-MiniLM-L-12-v2 (larger, more accurate)

# ============================================================================
# Document Parser Configuration
# ============================================================================

# PDF Parser Settings
# Options: 'pymupdf' or 'unstructured'
# - pymupdf: Faster, lighter, good for most PDFs
# - unstructured: Better for complex layouts, tables, and images
PDF_PARSER_BACKEND=pymupdf
PDF_EXTRACT_IMAGES=false
PDF_EXTRACT_TABLES=true

# Image Parser (OCR) Settings
# Tesseract OCR language codes
# Examples: 'eng' (English), 'fra' (French), 'deu' (German), 'spa' (Spanish)
# Multiple languages: 'eng+fra' or 'eng+deu'
OCR_LANGUAGE=eng

# Markdown Parser Settings
# Strip markdown formatting when parsing
MARKDOWN_STRIP_FORMATTING=false

# Text Parser Settings
# Default text encoding
TEXT_ENCODING=utf-8

# ============================================================================
# Document Input Configuration
# ============================================================================
# Default directory path for input documents
DOCUMENTS_INPUT_PATH=./documents

# Search subdirectories recursively
DOCUMENTS_RECURSIVE=true

# ============================================================================
# Batch Processing Configuration
# ============================================================================
# Maximum number of documents to process in parallel
MAX_PARALLEL_DOCUMENTS=5

# Skip files larger than this (in MB, 0 = no limit)
MAX_FILE_SIZE_MB=100

# ============================================================================
# Logging and Monitoring
# ============================================================================
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Enable detailed token usage logging
LOG_TOKEN_USAGE=true

# Enable parsing statistics
LOG_PARSING_STATS=true

# ============================================================================
# Advanced Settings (Optional)
# ============================================================================

# Circuit breaker settings for external services
CIRCUIT_BREAKER_ENABLED=true
CIRCUIT_BREAKER_THRESHOLD=5
CIRCUIT_BREAKER_TIMEOUT=60

# Retry settings for failed operations
MAX_RETRIES=3
RETRY_DELAY=1

# Cache settings (if implementing caching)
ENABLE_CACHE=false
CACHE_TTL=3600

# API rate limiting
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_PERIOD=60


